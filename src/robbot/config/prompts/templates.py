"""
Sistema de prompts para Gemini AI.

Este m√≥dulo centraliza todos os prompts usados no sistema,
permitindo versionamento e f√°cil manuten√ß√£o.
"""

import logging
from typing import Optional

logger = logging.getLogger(__name__)


class PromptTemplates:
    """
    Templates de prompts para diferentes casos de uso.
    
    Responsabilidades:
    - Fornecer prompts padronizados
    - Permitir personaliza√ß√£o com vari√°veis
    - Versionar prompts
    """
    
    VERSION = "1.0.0"
    
    # ========== PROMPT BASE ==========
    BASE_SYSTEM_PROMPT = """Voc√™ √© um assistente virtual inteligente de uma empresa de vendas.

INSTRU√á√ïES GERAIS:
- Seja educado, profissional e prestativo
- Responda em portugu√™s do Brasil
- Mantenha respostas objetivas (m√°ximo 3 par√°grafos)
- Use informa√ß√µes do contexto quando dispon√≠vel
- Se n√£o souber algo, seja honesto e ofere√ßa ajuda alternativa
- N√£o invente informa√ß√µes ou pre√ßos

CONTEXTO DA CONVERSA:
{context}

HIST√ìRICO:
{history}
"""

    # ========== DETEC√á√ÉO DE INTEN√á√ÉO ==========
    INTENT_DETECTION_PROMPT = """Analise a mensagem do usu√°rio e identifique a INTEN√á√ÉO principal.

MENSAGEM: "{message}"

CONTEXTO ANTERIOR:
{context}

INTEN√á√ïES POSS√çVEIS:
1. INTERESSE_PRODUTO - Cliente interessado em produtos/servi√ßos
2. DUVIDA_TECNICA - D√∫vidas sobre funcionamento/especifica√ß√µes
3. ORCAMENTO - Solicita√ß√£o de or√ßamento/pre√ßo
4. AGENDAMENTO - Deseja agendar reuni√£o/visita
5. RECLAMACAO - Problema ou insatisfa√ß√£o
6. INFORMACAO - Busca informa√ß√µes gerais
7. SAUDACAO - Cumprimento inicial
8. DESPEDIDA - Finaliza√ß√£o da conversa
9. CONFIRMACAO - Confirmar interesse/compra
10. OUTRO - N√£o se encaixa nas anteriores

Responda APENAS com o nome da inten√ß√£o (ex: INTERESSE_PRODUTO).
"""

    # ========== SCORING DE MATURIDADE ==========
    MATURITY_SCORING_PROMPT = """Avalie o n√≠vel de MATURIDADE DO LEAD baseado na conversa.

CONVERSA ATUAL:
{conversation_text}

HIST√ìRICO DE INTERA√á√ïES:
{interaction_history}

CRIT√âRIOS DE AVALIA√á√ÉO:
1. Engajamento (0-25 pontos)
   - Frequ√™ncia de respostas
   - Qualidade das perguntas
   - Tempo de resposta

2. Interesse (0-25 pontos)
   - Demonstra necessidade clara
   - Fez perguntas espec√≠ficas
   - Mencionou or√ßamento/timeline

3. Qualifica√ß√£o (0-25 pontos)
   - Tem poder de decis√£o
   - Tem budget
   - Timeline definido

4. Prontid√£o (0-25 pontos)
   - Urg√™ncia demonstrada
   - Pr√≥ximos passos claros
   - Sinais de fechamento

SCORE ATUAL: {current_score}

Analise a conversa e responda em JSON:
{{
    "score": <0-100>,
    "reasoning": "<breve explica√ß√£o>",
    "next_action": "<recomenda√ß√£o>"
}}
"""

    # ========== GERA√á√ÉO DE RESPOSTA ==========
    RESPONSE_GENERATION_PROMPT = """Gere uma resposta adequada para o cliente.

MENSAGEM DO CLIENTE: "{user_message}"

INTEN√á√ÉO DETECTADA: {intent}

CONTEXTO RELEVANTE:
{context}

INFORMA√á√ïES DO LEAD:
- Score de Maturidade: {maturity_score}/100
- Status: {lead_status}
- √öltima Intera√ß√£o: {last_interaction}

INSTRU√á√ïES ESPEC√çFICAS:
- Responda de forma natural e conversacional
- Seja proativo sugerindo pr√≥ximos passos
- Se score > 70, seja mais direto sobre fechamento
- Se score < 40, foque em educar e qualificar
- Mencione informa√ß√µes do contexto quando relevante

Gere APENAS a resposta (sem meta-informa√ß√µes).
"""

    # ========== EXTRA√á√ÉO DE CONTEXTO ==========
    CONTEXT_EXTRACTION_PROMPT = """Extraia informa√ß√µes-chave da mensagem para contexto.

MENSAGEM: "{message}"

EXTRAIA (quando presente):
- Produtos/servi√ßos mencionados
- Valores/or√ßamento mencionados
- Datas/prazos mencionados
- Prefer√™ncias do cliente
- Obje√ß√µes ou preocupa√ß√µes
- Decisores envolvidos

Responda em JSON:
{{
    "products": ["produto1", "produto2"],
    "budget": "<valor ou null>",
    "timeline": "<prazo ou null>",
    "preferences": ["pref1", "pref2"],
    "objections": ["obj1"],
    "decision_makers": ["pessoa1"]
}}
"""

    # ========== FALLBACK ==========
    FALLBACK_PROMPT = """Gere uma resposta de fallback apropriada.

SITUA√á√ÉO: {situation}
√öLTIMO ERRO: {error}

INSTRU√á√ïES:
- Seja educado e mostre que est√° tentando ajudar
- Ofere√ßa alternativas (falar com humano, tentar reformular)
- N√£o exponha detalhes t√©cnicos do erro
- Mantenha tom profissional

Gere resposta de fallback.
"""

    @classmethod
    def format_base_prompt(
        cls,
        context: str = "",
        history: str = ""
    ) -> str:
        """
        Formatar prompt base com contexto e hist√≥rico.
        
        Args:
            context: Contexto relevante da conversa
            history: Hist√≥rico de mensagens
            
        Returns:
            Prompt formatado
        """
        return cls.BASE_SYSTEM_PROMPT.format(
            context=context or "[Nenhum contexto dispon√≠vel]",
            history=history or "[Primeira intera√ß√£o]"
        )

    @classmethod
    def format_intent_prompt(cls, message: str, context: str = "") -> str:
        """
        Formatar prompt de detec√ß√£o de inten√ß√£o.
        
        Args:
            message: Mensagem do usu√°rio
            context: Contexto anterior
            
        Returns:
            Prompt formatado
        """
        return cls.INTENT_DETECTION_PROMPT.format(
            message=message,
            context=context or "[Sem contexto anterior]"
        )

    @classmethod
    def format_maturity_prompt(
        cls,
        conversation_text: str,
        interaction_history: str = "",
        current_score: int = 0
    ) -> str:
        """
        Formatar prompt de scoring de maturidade.
        
        Args:
            conversation_text: Texto da conversa atual
            interaction_history: Hist√≥rico de intera√ß√µes
            current_score: Score atual do lead
            
        Returns:
            Prompt formatado
        """
        return cls.MATURITY_SCORING_PROMPT.format(
            conversation_text=conversation_text,
            interaction_history=interaction_history or "[Primeira conversa]",
            current_score=current_score
        )

    @classmethod
    def format_response_prompt(
        cls,
        user_message: str,
        intent: str,
        context: str = "",
        maturity_score: int = 0,
        lead_status: str = "NEW",
        last_interaction: str = "Agora"
    ) -> str:
        """
        Formatar prompt de gera√ß√£o de resposta.
        
        Args:
            user_message: Mensagem do usu√°rio
            intent: Inten√ß√£o detectada
            context: Contexto relevante
            maturity_score: Score de maturidade
            lead_status: Status do lead
            last_interaction: √öltima intera√ß√£o
            
        Returns:
            Prompt formatado
        """
        return cls.RESPONSE_GENERATION_PROMPT.format(
            user_message=user_message,
            intent=intent,
            context=context or "[Sem contexto]",
            maturity_score=maturity_score,
            lead_status=lead_status,
            last_interaction=last_interaction
        )

    @classmethod
    def format_context_extraction_prompt(cls, message: str) -> str:
        """
        Formatar prompt de extra√ß√£o de contexto.
        
        Args:
            message: Mensagem para extrair contexto
            
        Returns:
            Prompt formatado
        """
        return cls.CONTEXT_EXTRACTION_PROMPT.format(message=message)

    @classmethod
    def format_fallback_prompt(cls, situation: str, error: str = "") -> str:
        """
        Formatar prompt de fallback.
        
        Args:
            situation: Descri√ß√£o da situa√ß√£o
            error: Erro ocorrido (opcional)
            
        Returns:
            Prompt formatado
        """
        return cls.FALLBACK_PROMPT.format(
            situation=situation,
            error=error or "N√£o especificado"
        )

    @classmethod
    def get_version(cls) -> str:
        """Obter vers√£o dos prompts."""
        return cls.VERSION


# Singleton global
_prompt_templates: Optional[PromptTemplates] = None


def get_prompt_templates() -> PromptTemplates:
    """
    Obter inst√¢ncia singleton de PromptTemplates.
    
    Returns:
        PromptTemplates singleton
    """
    global _prompt_templates
    
    if _prompt_templates is None:
        _prompt_templates = PromptTemplates()
        logger.info(f"üéØ PromptTemplates inicializado (version={PromptTemplates.VERSION})")
    
    return _prompt_templates
